

# 常用命令



```sh
mvn clean install package -Dmaven.test.skip=true

mvn clean install package -Dmaven.test.skip=true  -P dev


```















# 数据源



```xml
<dependency>
    <groupId>com.oracle</groupId>
    <artifactId>ojdbc8</artifactId>
    <version>8</version>
</dependency>
```





安装 oracle 驱动

```sh
mvn install:install-file -DgroupId=com.oracle -DartifactId=ojdbc8 -Dversion=8 -Dpackaging=jar -Dfile=ojdbc-8.jar
```







# Linux用户问题



![](./img/tez_error.png)





```sh
sh /opt/lyk/ssh_do_all.sh "usermod -a -G sjzt liuxingping"



```













# 离线同步

## Datax

官方地址：https://github.com/alibaba/DataX

```java
public enum DbType {
    
    MYSQL(0, "mysql"),
    HIVE(2, "hive"),
    CLICKHOUSE(4, "clickhouse"),
    ORACLE(5, "oracle"),
    MONGODB(12, "mongodb"),
    TIDB(13,"tidb")
    
    @EnumValue
    private final int code;
    private final String descp;
    
    public static DbType of(int type) {
        if (DB_TYPE_MAP.containsKey(type)) {
            return DB_TYPE_MAP.get(type);
        }
      	return null;
    }
    
}
```



## Json

重要的类

```java
com.alibaba.fastjson.JSONObject、
com.fasterxml.jackson.databind.ObjectMapper
com.fasterxml.jackson.databind.JsonNode
```



```java
public abstract class JSON{
    JSONObject parseObject(String text)
}
```











## 获取表/字段

获取连接

```java
Class.forName(getDriverClassName(type));
try {
    if (type != DbType.HIVE.getCode()){
        connection = DriverManager.getConnection(url, username, password);
    } else {
        HiveConnectionParam baseConnectionParam = JSON.parseObject(connectionInfo, HiveConnectionParam.class);
        baseConnectionParam.setJdbcUrl(url);
        try {
            connection = DataSourceClientProvider.getInstance().getConnection(DbType.HIVE, baseConnectionParam);
        } catch (ExecutionException e) {
            log.error("获取hive连接错误, " + e, e);
            throw new RuntimeException(e);
        }
    }
} catch (SQLException e) {
    log.error(e.toString(), e);
}
```



获取表字段

```java
if (type == DbType.MYSQL.getCode() || type == DbType.TIDB.getCode()){
    statement.execute(this.getUseDatabaseSql(type, datasourceName));
    rs = statement.executeQuery("DESCRIBE " + tableName);
    while (rs.next()) {
        columnNameList.add(rs.getString("Field"));
        columnTypeList.add(rs.getString("Type"));
    }
}
if (type == DbType.ORACLE.getCode()){
    columnNameList = dataBaseUtils.getColumnNameList(connection, tableName);
    columnTypeList = dataBaseUtils.getColumnTypeList(connection, tableName, columnNameList.size());
}
```







## MySQL_to_hive

| 来源                    | 去向       | 备注 |
| ----------------------- | ---------- | ---- |
| audit_result （carbon） | bitnei_ods |      |



![](./img/mysql_nopart.png)











## Oracle_to_hive



## tidb_to_hive



## MongoDB_to_hive



## hive_to_hive









# 数据表管理





# 生产环境

```sql
$ sudo mysql -u root -p

CREATE USER 'new_user'@'localhost' IDENTIFIED BY 'password';
GRANT SELECT, INSERT, UPDATE, DELETE ON database.* TO 'new_user'@'localhost
FLUSH PRIVILEGES;
```







```java
20.20.5.11:default
20.20.5.12:default
20.20.5.13:default
scp dirs to 20.20.5.11//opt/services/dolphinscheduler starting

start to scp bin to 20.20.5.11//opt/services/dolphinscheduler
start to scp master-server to 20.20.5.11//opt/services/dolphinscheduler
start to scp worker-server to 20.20.5.11//opt/services/dolphinscheduler
start to scp alert-server to 20.20.5.11//opt/services/dolphinscheduler
start to scp api-server to 20.20.5.11//opt/services/dolphinscheduler
start to scp ui to 20.20.5.11//opt/services/dolphinscheduler
start to scp tools to 20.20.5.11//opt/services/dolphinscheduler

scp dirs to 20.20.5.11//opt/services/dolphinscheduler complete


scp dirs to 20.20.5.12//opt/services/dolphinscheduler starting
```















# 补数据

Apache DolpinScheduler 补数功能



补数的主要策略是生成对应的工作流，包括串行补数和并行补数。

未配置定时或已配置定时并定时状态下线：根据所选的时间范围结合定时默认配置(每天0点)进行补数。

已配置定时并定时状态上线：根据所选的时间范围结合定时配置进行补数，比如该工作流调度日期为7月7号到7月10号，配置了定时（每日凌晨5点运行）



```java
// 并行流程
start-process-instance->createCommand->RUN_MODE_PARALLEL->insertCommand->MasterSchedulerBootstrap:findCommands->WorkflowExecuteRunnable:handleEvents->processComplementData->needComplementProcess->finish

// 串行流程
start-process-instance->createCommand->RUN_MODE_SERIAL->insertCommand->MasterSchedulerBootstrap:findCommands->WorkflowExecuteRunnable:handleEvents->processComplementData->needComplementProcess->finish
```





![](./img/bushuju_test.png)



任务内容

```sql
select ${day}
```

参数设置

<img src="./img/canshu-1day.png" style="zoom:67%;" />

补数2-4号

实际执行打印1-2号，符合预期





```java
protected int createComplementCommandList(String scheduleTimeParam, RunMode runMode, Command command,
                                              Integer expectedParallelismNumber,
                                              ComplementDependentMode complementDependentMode)
```



```
{"complementStartDate":"2023-09-07 00:00:00","complementEndDate":"2023-09-09 00:00:00"}

RUN_MODE_SERIAL

Command(id=null, commandType=COMPLEMENT_DATA, processDefinitionCode=10724463913984, executorId=1859, commandParam={}, taskDependType=TASK_POST, failureStrategy=CONTINUE, warningType=NONE, warningGroupId=0, scheduleTime=null, startTime=Tue Sep 26 11:01:24 CST 2023, processInstancePriority=MEDIUM, updateTime=Tue Sep 26 11:01:24 CST 2023, workerGroup=default, environmentCode=null, dryRun=0, processInstanceId=0, processDefinitionVersion=4)

null

OFF_MODE
```











# 接口梳理

## 数据工厂

### 任务详情查询接口

```sql
SELECT t.code                                                                              taskCode,
       t.name                                                                              taskName,
       case when online.task_params is null then t.task_params else online.task_params end taskParams,
       p.process_definition_code                                                           processCode,
       t.description,
       u.user_name                                                                         userName,
       t.user_id                                                                           userId,
       t.task_type                                                                         taskType
FROM t_ds_task_definition_not_online t
         LEFT JOIN t_ds_process_task_relation p ON t.code = p.post_task_code
         LEFT JOIN t_ds_user u ON t.user_id = u.id
         LEFT JOIN t_ds_task_definition online ON t.relation_code = online.code
WHERE t.code =10853860273440 AND t.project_code=9063908292224
```







```sh
taskDefinitionJson: [{"code":10745667140096,"delayTime":"0","description":"","environmentCode":8500162445248,"failRetryInterval":"1","failRetryTimes":"0","flag":"YES","name":"canshu_shengchan_001","taskGroupId":null,"taskGroupPriority":null,"taskParams":{"localParams":[{"prop":"day01","direct":"IN","type":"INTEGER","value":"123456"}],"resourceList":[],"type":"MYSQL","datasource":120,"sql":"select ${day01}","sqlType":"0","preStatements":[],"postStatements":[],"segmentSeparator":"","displayRows":10},"taskPriority":"MEDIUM","taskType":"SQL","timeout":0,"timeoutFlag":"CLOSE","timeoutNotifyStrategy":"","workerGroup":"default","cpuQuota":-1,"memoryMax":-1,"taskExecuteType":"BATCH","version":1,"id":2641}]
taskRelationJson: [{"name":"","preTaskCode":0,"preTaskVersion":0,"postTaskCode":10745667140096,"postTaskVersion":1,"conditionType":"NONE","conditionParams":{}}]
locations: [{"taskCode":10745667140096,"x":251.13189697265625,"y":154.91433715820312}]
name: canshu_shengchan0001
tenantCode: default
executionType: PARALLEL
description: 
globalParams: []
timeout: 0
releaseState: OFFLINE
```







### 上游任务



添加条件 `INNER JOIN t_ds_task_definition_not_online tn ON td.code = tn.relation_code`

```xml
<select id="getUpstreamTaskNode" resultType="java.util.Map">
    SELECT distinct td.code taskCode, td.name taskName,tu.user_name userName,td.version taskVersion,td.create_time taskCreateTime
    FROM t_ds_task_definition td
    LEFT JOIN t_ds_process_task_relation pt ON ((td.code=pt.post_task_code AND td.version=pt.post_task_version) OR (td.code=pt.pre_task_code AND td.version=pt.pre_task_version))
    LEFT JOIN t_ds_process_definition pd ON pt.process_definition_code = pd.code AND pt.process_definition_version=pd.version
    LEFT JOIN t_ds_user tu ON td.user_id=tu.id
    INNER JOIN t_ds_task_definition_not_online tn ON td.code = tn.relation_code
    WHERE td.project_code = #{projectCode} AND td.flag=1 AND pd.release_state=1 AND td.task_type!='DEPENDENT'
</select>
```



### 删除任务还原后再上线

```sh
[ERROR] 2023-09-15 13:10:29.625 +0800 org.apache.dolphinscheduler.api.exceptions.ApiExceptionHandler:[58] - start process instance error
org.apache.ibatis.binding.BindingException: Mapper method 'org.apache.dolphinscheduler.dao.mapper.ProcessTaskRelationMapper.queryRelationCode attempted to return null from a method with a primitive return type (long).
```



```java
long processDefinitionCode = this.queryRelationCode(projectCode, relationCode);
```

xml

```xml
<select id="queryRelationCode" resultType="java.lang.Long">
    SELECT process_definition_code FROM t_ds_process_task_relation WHERE project_code=#{projectCode}
                                                            AND post_task_code =#{postTaskCode}
                                                            OR pre_task_code =#{postTaskCode} LIMIT 1
</select>
```



### sql校验

`HiveSqlParseUtils` 类





### 重跑参数

```xml
<update id="updateRetryParameter">
    UPDATE t_ds_task_definition
        SET rerun_code= #{failureStrategy} ,
            fail_retry_times = #{failRetryTimes} ,
            fail_retry_interval = #{failRetryInterval},
            update_time = sysdate()
    WHERE project_code = #{projectCode} AND code = #{taskDefinitionCode}
</update>
```









# 失败任务邮件报警

- `org.springframework.mail.javamail` 包的 `JavaMailSender` 来发送邮件

  - ```
    javaMailSender.send(mimeMessage);
    ```

- `MimeMessage`是 `JavaMail API` 中的一个类，提供了用于设置和获取电子邮件消息的各种属性和内容。



```yml
spring:
  mail:
    host: smtp.qq.com
    username: 872767407@qq.com
    password: ocpweizqaidmbgaa
    port: 587
    default-encoding: UTF-8
    properties:
      mail:
        #配置SSL 加密工厂
        smtp:
          ssl:
            #本地测试，先放开ssl
            enable: false
            required: false
        #开启debug模式，这样邮件发送过程的日志会在控制台打印出来，方便排查错误
        debug: true
  thymeleaf:
    cache: true
    prefix: classpath:/templates/
    suffix: html
```



```yml
spring:
  mail:
    host: smtp.exmail.qq.com
    username: sjzt@bitnei.cn
    password: Samsung.123
    port: 465
    default-encoding: UTF-8
    properties:
      mail:
        #配置SSL 加密工厂
        smtp:
          ssl:
            #本地测试，先放开ssl
            enable: false
            required: false
        #开启debug模式，这样邮件发送过程的日志会在控制台打印出来，方便排查错误
        debug: true
```



报错

```sh
javax.mail.MessagingException: Could not connect to SMTP host: smtp.xxx.com, port: 465, response: -1
```

解决

```java
props.setProperty("mail.smtp.socketFactory.class", "javax.net.ssl.SSLSocketFactory");
props.put("mail.smtp.ssl.enable", true);
//设置安全证书
props.put("mail.smtp.ssl.protocols", "TLSv1.2");
```

参考：https://www.cnblogs.com/luoxiao1104/p/16672860.html





```java
@Configuration
public class MyConfig {

    @Value("${spring.mail.host:smtp.exmail.qq.com}")
    private String host;

    @Value("${spring.mail.username:sjzt@bitnei.cn}")
    private String username;

    @Value("${spring.mail.password:Samsung.123}")
    private String password;

    @Value("${spring.mail.port:465}")
    private String port;

    @Bean
    public JavaMailSender javaMailSender() {
        JavaMailSenderImpl mailSender = new JavaMailSenderImpl();
        mailSender.setHost(host);
        mailSender.setUsername(username);
        mailSender.setPassword(password);
        mailSender.setPort(Integer.parseInt(port));
        Properties props = new Properties();
        // 其他属性设置
        props.setProperty("mail.smtp.socketFactory.class", "javax.net.ssl.SSLSocketFactory");
        props.put("mail.smtp.ssl.enable", "true");
        props.put("mail.smtp.ssl.protocols", "TLSv1.2");

        mailSender.setJavaMailProperties(props);
        return mailSender;
    }
}
```







# 安全中心

部门



## kebors

```sh
kadmin.local -q "ktadd -k /home/yanglu/yanglu.keytab -norandkey yanglu"


```





# 数据集市

bug 我的数据 根据数据库id搜索无效



















# 导入数据

## MultipartFile

`org.springframework.web.multipart` 下，

```java
public interface MultipartFile extends InputStreamSource {
    String getName();
    
    @Nullable
	String getOriginalFilename();
}
```









## JsonNode

```java
public abstract class JsonNode
    extends JsonSerializable.Base // i.e. implements JsonSerializable
    implements TreeNode, Iterable<JsonNode>
{
}
```









## 上传csv/txt文件导入数据

控制层

```java
/**
 * 数据表导入数据
 * @param tableId 数据表ID
 * @param uploadFile 上传文件
 * @param fileType 文件类型
 * @param separator 分隔符
 * @param isFirstTitle 是否首行标题
 */
@PostMapping("/importQualityData")
public Result<Object> importQualityData(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
                                        @RequestParam("tableId") int tableId,
                                        @RequestParam("uploadFile") MultipartFile uploadFile,
                                        @RequestParam("fileType") int fileType,
                                        @RequestParam("separator") String separator,
                                        @RequestParam("startLine") int startLine,
                                        @RequestParam("isFirstTitle") boolean isFirstTitle
) throws SQLException, IOException {
    return customizationTableManageService.importQualityDataByType(loginUser, tableId, uploadFile, fileType,
            separator, startLine, isFirstTitle);
}
```



service 层

```java
@Transactional
@Override
public Result<Object> importQualityDataByType(User loginUser, int tableId, MultipartFile uploadFile, int fileType,
                                              String separator, int startLine, boolean isFirstTitle) {
    Result<Object> result = new Result<>();
    // separator 处理
    if (separator.equals("逗号")) {
        separator = ",";
    }
    if (separator.equals("分号")) {
        separator = ";";
    }
    if (separator.equals("Tab")) {
        separator = "\\t";
    }
    if (separator.equals("空格")) {
        separator = " ";
    }
    // 用户输入分隔符校验
    String delimiterStr = getDelimiter(uploadFile);
    if (!delimiterStr.equals(separator)){
        result.setCode(200);
        result.setMsg("所选分隔符与文件分隔符不匹配，请重新校验。");
        return result;
    }
    // 文件处理
    uploadFile = processUploadFile(uploadFile, separator, startLine, isFirstTitle, tableId);
    // 数据导入
    logger.info("processUploadFile finished");
    result = importData(loginUser, tableId, uploadFile, fileType, separator, startLine, isFirstTitle);

    return result;
}
```



文件处理 `processUploadFile`

```java
// 文件处理
private MultipartFile processUploadFile(MultipartFile file, String separator, int startLine, boolean isFirstTitle, int tableId) {
    // 获取文件名
    String fileName = file.getOriginalFilename();
    // 从MultipartFile获取输入流
    BufferedReader reader = null;
    try {
        reader = new BufferedReader(new InputStreamReader(file.getInputStream()));
    } catch (IOException e) {
        logger.error(e.getMessage(), e);
    }
    // 创建一个新的MultipartFile来保存修改后的内容
    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
    BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(outputStream));
    String line = "";

    int count = 0;
    // 是否首行为标题
    if (isFirstTitle) {
        try {
            if (reader != null) {
                line = reader.readLine();
            }
        } catch (IOException e) {
            logger.error(e.getMessage(), e);
        }
        count = 1;
    }

    // 跳过行数
    for (int i = 0; i < startLine - count; i++) {
        try {
            if (reader != null) {
                reader.readLine();
            }
        } catch (IOException e) {
            logger.error(e.getMessage(), e);
        }
    }

    while (true) {
        try {
            if (!((line = reader.readLine()) != null)) break;
        } catch (IOException e) {
            logger.error(e.getMessage(), e);
        }
        // 将修改后的行写入输出流
        try {
            writer.write(line);
            writer.newLine();
        } catch (IOException e) {
            logger.error(e.getMessage(), e);
        }
    }
    try {
        writer.flush();
        writer.close();
    } catch (IOException e) {
        logger.error(e.getMessage(), e);
    }
    // 将修改后的内容转换为字节数组并创建新的MultipartFile对象
    byte[] bytes = outputStream.toByteArray();
    return new MultipartFile() {
        @Override
        public String getName() {
            return file.getName();
        }

        @Override
        public String getOriginalFilename() {
            return fileName;
        }

        @Override
        public String getContentType() {
            return file.getContentType();
        }

        @Override
        public boolean isEmpty() {
            return bytes.length == 0;
        }

        @Override
        public long getSize() {
            return bytes.length;
        }

        @Override
        public byte[] getBytes() throws IOException {
            return bytes;
        }

        @Override
        public InputStream getInputStream() throws IOException {
            return new ByteArrayInputStream(bytes);
        }

        @Override
        public void transferTo(File file) throws IOException, IllegalStateException {
            FileOutputStream fileOutputStream = new FileOutputStream(file);
            fileOutputStream.write(bytes);
            fileOutputStream.close();
        }
    };
}
```



导入数据 `importData`

```java
@Transactional
public Result<Object> importData(User loginUser, int tableId, MultipartFile uploadFile, int fileType,
                                 String separator, int startLine, boolean isFirstTitle) {
    Table table = customizationTableManageMapper.selectById(tableId);
    //1 creat tmp as/like a
    // 获取元数据
    String databaseName = table.getDatabaseName();
    String ddl = getTableDdl(table.getTableName(), table.getDatabaseName());
    logger.info("table ddl is: {}", ddl);

    int startIndex = ddl.indexOf("(");
    int endIndex = ddl.indexOf(")", startIndex);
    String fieldStr = ddl.substring(startIndex, endIndex + 1);
    logger.info("fieldStr is: {}", fieldStr);

    // 如果存在PARTITIONED BY，则提取PARTITIONED BY后面的括号内容
    int partitionedByIndex = ddl.indexOf("PARTITIONED BY");
    if (partitionedByIndex != -1) {
        int secondBracketStartIndex = ddl.indexOf("(", partitionedByIndex);
        int secondBracketEndIndex = ddl.indexOf(")", secondBracketStartIndex);
        String secondContent = ddl.substring(secondBracketStartIndex + 1, secondBracketEndIndex).trim();

        // 拼接两个内容
        fieldStr = fieldStr.substring(0, fieldStr.length() - 1) + ", " + secondContent + ")";
    }
    logger.info("fieldStr is: {}", fieldStr);


    StringBuilder sb = new StringBuilder();
    sb.append("CREATE TABLE ").append("`")
            .append(table.getTableName())
            .append("_tmp` ")
            .append(fieldStr)
            .append(" ROW FORMAT DELIMITED FIELDS TERMINATED BY '")
            .append(separator)
            .append("'")
            .append(" stored as textfile");
    logger.info("create tmp table with sql: {}", sb);

    //2 load
    //上传文件到HDFS
    String fullName = getFullName("/", uploadFile.getOriginalFilename());
    if (!upload(loginUser, fullName, uploadFile, FILE)) {
        logger.error("upload resource: {} file: {} failed.", RegexUtils.escapeNRT(uploadFile.getOriginalFilename()),
                RegexUtils.escapeNRT(uploadFile.getOriginalFilename()));
        throw new ServiceException(
                String.format("upload resource: %s file: %s failed.", uploadFile.getOriginalFilename(), uploadFile.getOriginalFilename()));
    }

    // 建表
    DatabaseUtils dataBase = new DatabaseUtils();
    Connection connection = null;
    Statement statement = null;

    String realDatabaseName = getDatabaseName(table);
    StringBuilder loadSqlSb = new StringBuilder();
    loadSqlSb.append("load data inpath '/dolphinscheduler/dolphinscheduler/resources/")
            .append(uploadFile.getOriginalFilename())
            .append("' into table ")
            .append(realDatabaseName)
            .append(".")
            .append(table.getTableName())
            .append("_tmp");
    //String loadSql = "load data inpath '/dolphinscheduler/dolphinscheduler/resources/" + uploadFile.getOriginalFilename() + "' into table " + realDatabaseName + "." + table.getTableName() + "_tmp";
    String insertSql = "insert into " + realDatabaseName + "." + table.getTableName() + " select * from " + table.getTableName() + "_tmp";
    String deleteSql = "drop table " + table.getTableName() + "_tmp";

    try {
        // 建立JDBC连接
        connection = getConnection(dataBase, databaseName);
        statement = connection.createStatement();
        // 执行建表
        statement.execute(getUseDatabaseSql(databaseName));
        logger.info("drop table with sql: {}", deleteSql);
        statement.execute(deleteSql);
        logger.info("create table with sql: {}", sb);
        statement.execute(sb.toString());

        statement.execute(loadSqlSb.toString());
        //3 insert A select tmp
        statement.execute(insertSql);
        //4 drop
        statement.execute(deleteSql);

    } catch (SQLException e) {
        logger.error(e.getMessage(), e);
        throw new RuntimeException("sql 错误！");
    } finally {
        DatabaseUtils.closeResources(connection, statement, null);
    }

    Result<Object> result = new Result<>();
    result.setCode(Status.SUCCESS.getCode());
    result.setMsg(Status.SUCCESS.getMsg());
    return result;
}
```





## Streaming API

- apache commons-fileupload：https://commons.apache.org/proper/commons-fileupload/streaming.html
- stackoverflow answer：https://stackoverflow.com/questions/32782026/springboot-large-streaming-file-upload-using-apache-commons-fileupload



















## OOM

```shell
JAVA_OPTS=${JAVA_OPTS:-"-server -Duser.timezone=${SPRING_JACKSON_TIME_ZONE} -Dspring.profiles.active=dev -Xms2g -Xmx2g -Xmn1g -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5004 -XX:+PrintGCDetails -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError -Dsun.security.krb5.debug=true -XX:HeapDumpPath=dump.hprof"}
```



## 参数校验

```java
if (selectUsers.size() == 0){
    throw new RuntimeException("未选择授权对象！");
}
if (selectResources.size() == 0){
    throw new RuntimeException("未选择待授权资源");
}

// 使用isEmpty()方法来判断集合是否为空，与size()方法相比，isEmpty()方法更加简洁和直观
if (selectUsers.isEmpty()){
    throw new RuntimeException("未选择授权对象！");
}
if (selectResources.isEmpty()){
    throw new RuntimeException("未选择待授权资源");
}
```



## 日志

```java
log.info("待授权资源为：" + selectResource);
log.info("待授权资源为：{}", selectResource);
```



## Json

```java
@NotNull
private String getUseDatabaseSql(String databaseName) {
    String connectionInfo = dataSourceService.getConnectionInfo(DATASOURCE_TYPE, databaseName);
    LinkedHashMap<String, Object> json = JSON.parseObject(connectionInfo, LinkedHashMap.class, Feature.OrderedField);
    JSONObject jsonObject = new JSONObject(true);
    jsonObject.putAll(json);
    String database = jsonObject.getString("database");
    String useDatabaseSql = "USE " + database;
    return useDatabaseSql;
}
```



## 关于分页







mybatis

```java
List<Map> selectAllUser();
```



```xml
<select id="selectAllUser" resultType="java.util.HashMap">
    SELECT id,user_name userName
    FROM t_ds_user
    WHERE state = 1
</select>
```













