

# 0 写在前面

## 0.1推荐

### 视频

- B站黑马程序员
- B站尚硅谷





### 书籍

- 《offer来了》第三章 Java 并发编程

```bash
相对于传统的单线程，多线程能够在操作系统多核配置的基础上，能够更好地利用服务器的多个CPU资源，使程序运行起来更加高效。

Java 通过提供对多线程的支持，在一个进程内并发执行多个线程，每个线程都并行执行不同的任务，以满足编写高并发程序的要求。
```

### 博客

- Java 并发编程实战_王宝令（极客时间）
  - 第一部分：并发理论基础（13讲）
  - 第二部分：并发工具类（14讲）
  - 第三部分：并发设计模式（10讲）
  - 第四部分：案例分析（4讲）
  - 第五部分：其它并发模型（4讲）

- [Java多线程之锁优化与JUC常用类](https://juejin.cn/post/7106118341970493476#heading-8)



## 0.2如何学习？

### 跳出来，看全景

- 建立起一张并发领域全景图
  - 跳出来，看全景，可以让你的知识成体系，所学知识也融汇贯通起来，由点成线，由线及面，画出自己的知识全景图。
- 三个核心问题：分工、同步和互斥

![img](https://static001.geekbang.org/resource/image/11/65/11e0c64618c04edba52619f41aaa3565.png?wh=1349*756)

- 分工
  - 相关方法：Java SDK 并发包里的  `Executor`、`Fork/Join`、`Future` 
  - 相关设计模式：生产者 - 消费者、Thread-Per-Message、Worker Thread 模式等
- 协作
  - 在项目执行过程中，任务之间是有依赖的，一个任务结束后，依赖它的后续任务就可以开工了，后续工作怎么知道可以开工了呢？这个就是靠沟通协作了，这是一项很重要的工作。
  - **本质：一个线程执行完了一个任务，如何通知执行后续任务的线程开工。**
  - 协作一般和分工相关。
    - Java SDK 并发包里的 `Executor`、`Fork/Join`、`Future` 本质上都是分工方法，但同时也能解决线程协作的问题。
    - 另外，Java SDK 里提供的 `CountDownLatch`、`CyclicBarrier`、`Phaser`、`Exchanger` 也都是用来解决线程协作问题的。
  - 线程协作问题可描述为：当某个条件不满足时，线程需要等待，当某个条件满足时，线程需要被唤醒执行。如生产者 - 消费者模型。
  - **管程是解决并发问题的万能钥匙。**
    - 解决协作问题的核心技术是管程，上面提到的所有线程协作技术底层都是利用管程解决的。
    - 管程是一种解决并发问题的通用模型，除了能解决线程协作问题，还能解决下面我们将要介绍的互斥问题。
    - 关键是理解管程模型，学好它就可以解决所有问题。
    - 其次是了解 Java SDK 并发包提供的几个线程协作的工具类的应用场景，用好它们可以妥妥地提高你的工作效率。
- 互斥
  - 所谓互斥，指的是同一时刻，只允许一个线程访问共享变量。
  - 分工、同步主要强调的是性能，互斥强调正确性，用专业术语叫“线程安全”。
    - 并发程序里，当多个线程同时访问同一个共享变量的时候，结果是不确定的。
  - 导致不确定的主要源头是可见性问题、有序性问题和原子性问题。
    - 为了解决这三个问题，Java 语言引入了内存模型，内存模型提供了一系列的规则，利用这些规则，我们可以避免可见性问题、有序性问题，但是还不足以完全解决线程安全问题。
    - 解决线程安全问题的核心方案还是互斥。
  - 实现互斥的核心技术就是锁。
    - Java 语言里 `synchronized`、SDK 里的各种 `Lock` 都能解决互斥问题。（虽说锁解决了安全性问题，但同时也带来了性能问题，那如何保证安全性的同时又尽量提高性能呢？可以分场景优化）
    - Java SDK 里提供的 `ReadWriteLock`、`StampedLock` 就可以优化**读多写少场景**下锁的性能。
    - 使用**无锁**的数据结构，例如 Java SDK 里提供的**原子类**都是**基于无锁技术实现**的。
    - Java 提供的 `Thread Local` 和 `final` 关键字，还有一种 `Copy-on-write` 的模式。
  - 使用锁除了注意性能问题，还要注意死锁问题。（这部分内容较复杂，跨领域。）
    - 理解可见性：需要了解一些CPU和缓存的知识
    - 理解原子性：需要理解一些操作系统的知识
    - 无锁算法的实现：理解CPU缓存
      - 博览群书，建立起 CPU、内存、I/O 执行的模拟器。

### 钻进去，看本质

- 某个问题上钻进去，深入理解，找到本质。
  - 概念和结论是怎么来的，以及它们是用来解决什么问题的。
- 技术的本质是背后的理论模型。
  - 工程上的解决方案，一定要有理论做基础。
  - 在学习并发编程的过程中，探索它背后的理论是什么。
    - 比如，当看到 Java SDK 里面的条件变量 Condition 的时候，我会下意识地问，“它是从哪儿来的？是 Java 的特有概念，还是一个通用的编程概念？”
    - 当我知道它来自管程的时候，我又会问，“管程被提出的背景和解决的问题是什么？
    - 一路探索下来，发现 Java 语言里的并发技术基本都是有理论基础的，并且这些理论在其他编程语言里也有类似的实现。

## 0.3总结

- 探求理论本质，既能加深对技术本身的理解，也能拓展知识深度和广度，这是个一举多得的方法。
- java中的 JUC 就是来自`java.util.concurrent`包下的一些标准类或者接口，都是有关并发或者有关多线程的一些类和接口。



本文包括极客时间 并发编程专栏的并发理论基础（13讲）和并发工具类（14讲）2大部分。







# 1 可见性、原子性和有序性问题（并发编程bug的源头）

## 并发程序的背后

- 核心矛盾一直存在，CPU、内存、I/O 设备三者的速度差异。
  - CPU 是天上一天，内存是地上一年（假设 CPU 执行一条普通指令需要一天，那么 CPU 读写内存得等待一年的时间）。
  - 内存是天上一天，I/O 设备是地上十年。（内存和 I/O 设备的速度差异就更大了）
  - 单方面提高 CPU 性能是无效的。
    - 程序里大部分语句都要访问内存，有些还要访问 I/O。
    - 根据木桶理论（一只水桶能装多少水取决于它最短的那块木板），程序整体的性能取决于最慢的操作——读写 I/O 设备。
- 为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献。
  - CPU 增加了缓存，以均衡与内存的速度差异；
  - 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；
  - 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。
- 现在我们几乎所有的程序都默默地享受着这些成果，但是天下没有免费的午餐，并发程序很多诡异问题的根源也在这里。
- **【缓存】导致的【可见性】问题  ！【线程切换】导致的【原子性】问题！【指令优化】导致的【有序性】问题！**

## 缓存导致的可见性问题

- **所谓可见性：一个线程对共享变量的修改，另外一个线程能够立刻看到。**
- 在单核时代，所有的线程都是在一颗 CPU 上执行，CPU 缓存与内存的数据一致性容易解决。
  - 因为所有线程都是操作同一个 CPU 的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。
- 多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，**当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。**

<font color=red>此处应有对比图片一张！！！</font>

- 代码验证一下多核场景下的可见性问题
  - 假设线程 A 和线程 B 同时开始执行，那么第一次都会将 count=0 读到各自的 CPU 缓存里，执行完 count+=1 之后，各自 CPU 缓存里的值都是 1，同时写入内存后，我们会发现内存中是 1，而不是我们期望的 2。
  - 之后由于各自的 CPU 缓存里都有了 count 的值，两个线程都是基于 CPU 缓存里的 count 值来计算，所以导致最终 count 的值都是小于 20000 的。这就是缓存的可见性问题。
  - 如果改为循环 1 亿次，你会发现效果更明显，最终 count 的值接近 1 亿，而不是 2 亿。
  - 如果循环 10000 次，count 的值接近 20000，原因是两个线程不是同时启动的，有一个时差。

```java
public class Test {
    private static long count = 0;
    private void add10K() {
        int idx = 0;
        while(idx++ < 10000) {
            count += 1;
        }
    }
    public static long calc() throws InterruptedException {
        final Test test = new Test();
        // 创建两个线程，执行add()操作
        Thread th1 = new Thread(()->{
            test.add10K();
        });
        Thread th2 = new Thread(()->{
            test.add10K();
        });
        // 启动两个线程
        th1.start();
        th2.start();
        // 等待两个线程执行结束
        th1.join();
        th2.join();
        return count;
    }

    public static void main(String[] args) throws InterruptedException {
        System.out.println(Test.calc());
        // 16272（count 的值接近 20000）
        // 20000(多次)
    }
}
```

## 线程切换带来的原子性问题

- 早期单核CPU实现多进程。
- 关键词：操作系统、时间片、任务切换。CPU使用率、IO使用率。
- 支持多进程分时复用
  - 在操作系统的发展史上却具有里程碑意义，Unix 就是因为解决了这个问题而名噪天下的。
- 早期的操作系统基于进程来调度 CPU，不同进程间是不共享内存空间的
  - 所以进程要做任务切换就要切换内存映射地址
  - 而一个进程创建的所有线程，都是共享一个内存空间的，所以线程做任务切换成本就很低了。
  - 现代的操作系统都**基于更轻量的线程来调度**，现在我们提到的“任务切换”都是指“线程切换”。
- 高级语言里一条语句往往需要多条 CPU 指令完成。如count += 1，至少需要三条 CPU 指令
  - 指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器；
  - 指令 2：之后，在寄存器中执行 +1 操作；
  - 指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）。
- 操作系统做任务切换，可以发生在任何一条 CPU 指令执行完，是的，是 CPU 指令，而不是高级语言里的一条语句。
- 思考

```sh
# 对于这个问题:"如果是，那两个线程都有单独的cpu，为什么操作系统还要切换线程？",
首先CPU不是单独属于哪一个线程的,是所有线程所共有的,通过操作系统的调度来分配给线程执行指令.
其次,服务器运行时是会有很多线程的,一般远远大于CPU的核心数,即使线程数比CPU的核心数小,
操作系统的调度程序也不会让一个线程一直占用CPU这个资源,而是通过分配CPU时间片给选中的线程,
当CPU时间片用完后,调度程序会再次选择哪个线程来使用下一个CPU时间片,并将当前线程切换出来.

# 两个线程会不会在同一个CPU上执行指令,对于我们程序员而言,是随机的(假设CPU核心数>=2).
可能你第一次运行程序时,两个线程都在甲CPU上,而第二次两个线程都在乙CPU上,而第三次可能一个在甲CPU,一个在乙CPU.
我们要想写正确的程序,就是不管遇到哪一种情况,程序都能正确运行,输出确定的结果.
```



- 原子性
  - 所谓原子性，指一个或者多个操作在 CPU 执行的过程中不被中断的特性。
  - CPU 能保证的原子操作是 CPU 指令级别的。
  - 因此，很多时候我们需要在高级语言层面保证操作的原子性。

## 编译优化带来的有序性问题

- 所谓有序性，指的是程序按照代码的先后顺序执行。
- 编译器为了优化性能，有时候会改变程序中语句的先后顺序。
- Java领域经典案例：利用双重检查创建单例对象。

```shell
双重检查创建单例对象 JDK1.5之后，可以使用volatile关键字修饰变量来解决无序写入产生的问题。
因为volatile关键字的一个重要作用是禁止指令重排序，即保证不会出现内存分配、返回对象引用、初始化这样的顺序，
从而使得双重检测真正发挥作用。
```

示例代码

```java
public class Singleton {
  static Singleton instance;
  static Singleton getInstance(){
    if (instance == null) {
      synchronized(Singleton.class) {
        if (instance == null)
          instance = new Singleton();
        }
    }
    return instance;
  }
}
```

- 思考（高手都在评论区）
  - 对于有 volatile 语义声明的变量，线程 A 执行完后会强制将值刷新到内存中，线程 B 进行相关操作时会强制重新把内存中的内容写入到自己的缓存，这就涉及到了 volatile 的写入屏障问题，当然也就是所谓`happen-before`问题。
  - 在同步块里，线程也可能被操作系统剥夺cpu的使用权，但是其他线程此时是拿不到锁，所以其他线程不会执行同步块的代码。







# 2 Java内存模型（解决可见性和有序性问题）

- 合理的方案应该是按需禁用缓存以及编译优化。
- 所谓“按需禁用”其实就是指按照程序员的要求来禁用。只需要提供给程序员按需禁用缓存和编译优化的方法即可。

- Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。
  - 包括 volatile、synchronized 和 final 三个关键字
  - 以及六项 Happens-Before 规则



## 关于volatile

- 最原始的意义就是禁用 CPU 缓存。（并不是 Java 语言的特产，古老的 C 语言里也有）
- 声明一个 volatile 变量 volatile int x = 0
  - 告诉编译器，对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入。
- 线程 B 看到的变量 x 是多少呢？
  - 假设线程 A 执行 writer() 方法，按照 volatile 语义，会把变量 “v=true” 写入内存；
  - 假设线程 B 执行 reader() 方法，同样按照 volatile 语义，线程 B 会从内存中读取变量 v;
  - 如果线程 B 看到 “v == true” 时

```java
// 以下代码来源于【参考1】
class VolatileExample {
  int x = 0;
  volatile boolean v = false;
  public void writer() {
    x = 42;
    v = true;
  }
  public void reader() {
    if (v == true) {
      // 这里x会是多少呢？
    }
  }
}
```



## Happens-Before 规则（本质上是可见性）

- 前面一个操作的结果对后续操作是可见的。
- 正式说法：约束了编译器的优化行为，虽允许编译器优化，但是**要求编译器优化后一定遵守 Happens-Before 规则**。



具体内容有 6点：

- 1）程序的顺序性规则：在一个线程中，前面的操作Happens-Before于后续的任意操作。
  - 按照程序的顺序，第 6 行代码 “x = 42;” Happens-Before 于第 7 行代码 “v = true;”
- 2）volatile变量规则：对一个volatile变量的写操作Happens-Before于对这个volatile变量的读操作。
- 3）传递性规则：如果 A Happens-Before B，且 B Happens-Before C，那么A Happens-Before C。
  - 这就是 1.5 版本对 volatile 语义的增强，这个增强意义重大。
  - 1.5 版本的并发工具包（java.util.concurrent）就是靠 volatile 语义来搞定可见性的。
- 4）管程中锁的规则：指对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。
  - 管程指的是什么？是一种通用的同步原语，在 Java 中指的就是 `synchronized`，synchronized 是 Java 里对管程的实现。
  - **管程中的锁在 Java 里是隐式实现的。**（在进入同步块之前，会自动加锁，而在代码块执行完会自动释放锁，加锁以及释放锁都是编译器帮我们实现的。）

```java
synchronized (this) { //此处自动加锁
  // x是共享变量,初始值=10
  if (this.x < 12) {
    this.x = 12; 
  }  
} //此处自动解锁
```

- 5）线程 start() 规则：指主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。

```java
Thread B = new Thread(()->{
  // 主线程调用B.start()之前
  // 所有对共享变量的修改，此处皆可见
  // 此例中，var==77
});
// 此处对共享变量var修改
var = 77;
// 主线程启动子线程
B.start();
```

- 6）线程 join() 规则：关于线程等待。
  - 指主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作。当然所谓的“看到”，指的是对共享变量的操作。

### final

- final 修饰变量时，初衷是告诉编译器：这个变量生而不变，可以可劲儿优化。







# 3 互斥锁01（解决原子性问题）

分析一下
- 原子性问题的源头是线程切换。
- 而操作系统做线程切换是依赖 CPU 中断的，所以禁止 CPU 发生中断就能够禁止线程切换。
- 单核CPU场景下
  - 同一时刻只有一个线程执行，禁止 CPU 中断，意味着操作系统不会重新调度线程，也就是禁止了线程切换。
  - 获得 CPU 使用权的线程就可以不间断地执行，所以两次写操作一定是：要么都被执行，要么都没有被执行，具有原子性。
- 多核场景下
  - 同一时刻，有可能有两个线程同时在执行，一个线程执行在 CPU-1 上，一个线程执行在 CPU-2 上；
  - 此时禁止 CPU 中断，只能保证 CPU 上的线程连续执行，并不能保证同一时刻只有一个线程执行。
- 如果我们能够**保证对共享变量的修改是互斥的**，那么，无论是单核 CPU 还是多核 CPU，就都能保证原子性了。

## 简易锁模型

- 临界区：一段需要互斥执行的代码。
- 流程
  - 线程在进入临界区之前，首先尝试加锁 lock()，
  - 如果成功，则进入临界区，此时我们称这个线程持有锁；
  - 否则呢就等待，直到持有锁的线程解锁；
  - 持有锁的线程执行完临界区的代码后，执行解锁 unlock()。

- 两个容易忽视的点
  - 我们锁的是什么？
  - 我们保护的又是什么？（锁的是共享变量的访问，保护的是共享变量。）



## 改进锁模型

- 锁和锁要保护的资源是有对应关系的

- 分析
  - 为要保护资源 R创建一把锁 LR；
  - 针对这把锁 LR，我们还需在进出临界区时添上加锁操作和解锁操作。
  - 在锁 LR 和受保护资源之间，存在关联关系。



## Java 语言提供的锁技术：synchronized

- Java 语言提供的 synchronized 关键字，就是锁的一种实现。
- synchronized 关键字可以用来修饰方法，也可以用来修饰代码块。示例如下：

```java
class X {
  // 修饰非静态方法
  synchronized void foo() {
    // 临界区
  }
  // 修饰静态方法
  synchronized static void bar() {
    // 临界区
  }
  // 修饰代码块
  Object obj = new Object()；
  void baz() {
    synchronized(obj) {
      // 临界区
    }
  }
}  
```

- synchronized 里的加锁 lock() 和解锁 unlock() 锁定的对象在哪里呢？
  - 修饰代码块的时候，锁定了一个 obj 对象
  - 修饰方法的时候
    - 修饰静态方法的时候：锁定的是当前类的 Class 对象
    - 修饰非静态方法的时候：锁定的是当前实例对象 this

## 用 synchronized 解决 count+=1 问题

```java
class SafeCalc {
  long value = 0L;
  long get() {
    return value;
  }
  synchronized void addOne() {
    value += 1;
  }
}
```





## 锁和受保护资源的关系（N:1）

- get() 方法和 addOne() 方法是否存在并发问题？
  - 用两个锁保护一个资源。这个受保护的资源就是静态变量 value，两个锁分别是 this 和 SafeCalc.class。
  - 由于临界区 get() 和 addOne() 是用两个锁保护的，因此这两个临界区没有互斥关系，临界区 addOne() 对 value 的修改对临界区 get() 也没有可见性保证，这就导致并发问题了。

```java
class SafeCalc {
  static long value = 0L;
  synchronized long get() {
    return value;
  }
  synchronized static void addOne() {
    value += 1;
  }
}
```

## 总结

- 加锁能够保证执行临界区代码的互斥性。
- 多方面考量才能用好互斥锁。





# 4 互斥锁02（如何用一把锁保护多个资源？）

## 保护没有关联关系的多个资源

- 不同的资源用不同的锁保护，各自管各自的，很简单。
- 细粒度锁：用不同的锁对受保护资源进行精细化管理，能够提升性能。

```java
class Account {
  // 锁：保护账户余额
  private final Object balLock = new Object();
  // 账户余额  
  private Integer balance;
    
  // 锁：保护账户密码
  private final Object pwLock = new Object();
  // 账户密码
  private String password;

  // 取款
  void withdraw(Integer amt) {
    synchronized(balLock) {
      if (this.balance > amt){
        this.balance -= amt;
      }
    }
  } 
  // 查看余额
  Integer getBalance() {
    synchronized(balLock) {
      return balance;
    }
  }

  // 更改密码
  void updatePassword(String pw){
    synchronized(pwLock) {
      this.password = pw;
    }
  } 
  // 查看密码
  String getPassword() {
    synchronized(pwLock) {
      return password;
    }
  }
}
```

## 保护有关联关系的多个资源

```java
class Account {
  private int balance;
  // 转账
  synchronized void transfer(
      Account target, int amt){
    if (this.balance > amt) {
      this.balance -= amt;
      target.balance += amt;
    }
  } 
}
```

- 分析一下
  - 假设线程 1 执行账户 A 转账户 B 的操作，线程 2 执行账户 B 转账户 C 的操作。这两个线程分别在两颗 CPU 上同时执行，那它们是互斥的吗？
  - 不是。因为线程 1 锁定的是账户 A 的实例（A.this），而线程 2 锁定的是账户 B 的实例（B.this），所以这两个线程可以同时进入临界区 `transfer()`。

## 使用锁的正确姿势

- 只要我们的锁能覆盖所有受保护资源就可以。
  - this 是对象级别的锁，所以 A 对象和 B 对象都有自己的锁。
  - 如何让 A 对象和 B 对象共享一把锁呢？
    - 用 Account.class 作为共享的锁。



## 总结

- 对如何保护多个资源，关键是要分析多个资源之间的关系。
- 如果资源之间没有关系，很好处理，每个资源一把锁就可以了。
- 如果资源之间有关联关系，就要选择一个粒度更大的锁，这个锁应该能够覆盖所有相关的资源。
- 此外，还要梳理出有哪些访问路径，所有的访问路径都要设置合适的锁，这个过程可以类比一下门票管理。





# 5 死锁问题

- 使用细粒度锁（锁定两个账户）可以提高并行度，是性能优化的一个重要手段。

```java
class Account {
  private int balance;
  // 转账
  void transfer(Account target, int amt){
    // 锁定转出账户
    synchronized(this){     ①
      // 锁定转入账户
      synchronized(target){ ②
        if (this.balance > amt) {
          this.balance -= amt;
          target.balance += amt;
        }
      }
    }
  } 
}
```

- 代价：可能导致死锁。

- 死锁

  - 专业定义：一组互相竞争资源的线程因互相等待，导致“永久”阻塞的现象。
  - 可以借助资源分配图来可视化锁的占用情况（资源分配图是个有向图，它可以描述资源和线程的状态）
  - 死锁发生的4个条件（破坏其中一个）
    - 【互斥】，共享资源 X 和 Y 只能被一个线程占用；
    - 【占有且等待】，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X；
    - 【不可抢占】，其他线程不能强行抢占线程 T1 占有的资源；
    - 【循环等待】，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等待。
  - 如何预防死锁
    - 互斥这个条件我们没有办法破坏，因为我们用锁为的就是互斥！
    - （1）同时获取锁，不是分步获取。 
    - （2）如果获取不到主动释放已经持有的锁。
    - （3）按顺序获取锁。同样顺序去获取锁，不会存在循环。

- 预防死锁代码实践

  - 破坏占用且等待条件：同时申请资源 apply() 和同时释放资源 free()。

  ```java
  class Allocator {
    private List<Object> als = new ArrayList<>();
      
    // 一次性申请所有资源
    synchronized boolean apply(
      Object from, Object to){
      if(als.contains(from) || als.contains(to)){
        return false;  
      } else {
        als.add(from);
        als.add(to);  
      }
      return true;
    }
      
    // 归还资源
    synchronized void free(Object from, Object to){
      als.remove(from);
      als.remove(to);
    }
  }
  
  class Account {
    private Allocator actr;  // actr应该为单例
    private int balance;
    
    void transfer(Account target, int amt){    // 转账
      // 一次性申请转出账户和转入账户，直到成功
      while(!actr.apply(this, target));
      try{
        synchronized(this){   // 锁定转出账户           
          synchronized(target){    // 锁定转入账户       
            if (this.balance > amt){
              this.balance -= amt;
              target.balance += amt;
            }
          }
        }
      } finally {
        actr.free(this, target)
      }
    } 
  }
  ```

  - 破坏不可抢占条件：`java.util.concurrent` 这个包下面提供的 `Lock` 是可以轻松解决这个问题的。
  - 破坏循环等待条件：需要对资源进行排序，然后按序申请资源。

  ```java
  class Account {
    private int id;
    private int balance;
    // 转账
    void transfer(Account target, int amt){
      Account left = this        ①
      Account right = target;    ②
      if (this.id > target.id) { ③
        left = target;           ④
        right = this;            ⑤
      }                          ⑥
      // 锁定序号小的账户
      synchronized(left){
        // 锁定序号大的账户
        synchronized(right){ 
          if (this.balance > amt){
            this.balance -= amt;
            target.balance += amt;
          }
        }
      }
    } 
  }
  ```





# 6 用等待-通知机制优化循环等待

## 存在问题

- 如果转出账本和转入账本不满足同时在文件架上这个条件，就用死循环的方式来循环等待，核心代码如下：

```java
// 一次性申请转出账户和转入账户，直到成功
while(!actr.apply(this, target));
```

- 如果 apply() 操作耗时长，或者并发冲突量大的时候，循环等待这种方案就不适用了，因为在这种场景下，可能要循环上万次才能获取到锁，太消耗 CPU 了。

- 最好的方案：等待 - 通知机制机制
  - 线程首先获取互斥锁；
  - 当线程要求的条件不满足时，释放互斥锁，进入等待状态；
  - 当要求的条件满足时，通知等待的线程，重新获取互斥锁。

## 用 synchronized 实现等待 - 通知机制

在 Java 语言里，等待 - 通知机制可以有多种实现方式。
- 比如 Java 语言内置的 `synchronized` 配合 `wait()`、`notify()`、`notifyAll()` 这三个方法就能轻松实现。
- 等待队列和互斥锁是一对一的关系，每个互斥锁都有自己独立的等待队列。
- 当条件满足时调用 notify()，会通知等待队列（互斥锁的等待队列）中的线程，告诉它条件曾经满足过。
  - notify() 只能保证在通知时间点，条件是满足的。
- 一个运行时异常：`java.lang.IllegalMonitorStateException`



## 尽量使用 notifyAll()

- `notify()` 是会随机地通知等待队列中的一个线程，而 `notifyAll()` 会通知等待队列中的所有线程。

- `notify()` 可能导致某些线程永远不会被通知到。





# 7 安全性、活跃性以及性能问题

## 安全性问题

- 听过的描述：这个方法不是线程安全的，这个类不是线程安全的，等等。
- 线程安全：程序按照我们期望的执行，不要让我们感到意外。
- 分析原子性、可见性、有序性的情况：存在共享数据并且该数据会发生变化，通俗地讲就是有多个线程会同时读写同一数据。
- 数据竞争：当多个线程同时访问同一数据，并且至少有一个线程会写这个数据的时候，如果我们不采取防护措施，那么就会导致并发 Bug。（使用锁）
- 竞态条件：指的是程序的执行结果依赖线程执行的顺序。（使用锁）

## 活跃性问题

- 指的是某个操作无法执行下去。如死锁、活锁、饥饿等问题。
- 活锁问题
  - 定义：有时线程虽然没有发生阻塞，但仍然会存在执行不下去的情况（互相谦让）
  - 解决：尝试等待一个随机的时间就可以
- 饥饿问题
  - 定义：指的是线程因无法访问所需资源而无法执行下去的情况。
  - 解决
    - 保证资源充足
    - 公平地分配资源（适用场景更多）（主要是使用公平锁：先来后到，线程的等待是有顺序的。）
    - 避免持有锁的线程长时间执行



## 性能问题

- 使用锁的时候一定要关注对性能的影响。
- Java SDK 并发包里之所以有那么多东西，有很大一部分原因就是要提升在某个特定领域的性能。
- 从方案层面
  - 使用无锁的算法和数据结构。
    - 线程本地存储 (Thread Local Storage, TLS)、写入时复制 (Copy-on-write)、乐观锁等；
    - Java 并发包里面的原子类也是一种无锁的数据结构；
    - Disruptor 则是一个无锁的内存队列，性能都非常好……

  - 减少锁持有的时间。
    - 互斥锁本质上是将并行的程序串行化，所以要增加并行度，一定要减少持有锁的时间。
    - **使用细粒度的锁**，一个典型的例子就是 Java 并发包里的 ConcurrentHashMap，它使用了所谓分段锁的技术（这个技术后面我们会详细介绍）；
    - 还可以**使用读写锁**，也就是读是无锁的，只有写的时候才会互斥。

- 性能方面的度量指标
  - 吞吐量：指的是单位时间内能处理的请求数量。吞吐量越高，说明性能越好。
  - 延迟：指的是从发出请求到收到响应的时间。延迟越小，说明性能越好。
  - 并发量：指的是能同时处理的请求数量，一般来说随着并发量的增加、延迟也会增加。
    - 所以延迟这个指标，一般都会是基于并发量来说的。例如并发量是 1000 的时候，延迟是 50 毫秒。



## 总结

- 并发微观上涉及到原子性问题、可见性问题和有序性问题，宏观则表现为安全性、活跃性以及性能问题。

- 我们在设计并发程序的时候，主要是从宏观出发。安全性方面要注意数据竞争和竞态条件，活跃性方面需要注意死锁、活锁、饥饿等问题。







# 8 管程：并发编程的万能钥匙

- 有没有一种核心技术可以很方便地解决我们的并发问题呢？这个问题如果让我选择，我一定会选择管程技术。
- Java 语言在 1.5 之前，提供的唯一的并发原语就是管程，而且 1.5 之后提供的 SDK 并发包，也是以管程技术为基础的。
- 除此之外，C/C++、C# 等高级语言也都支持管程。
- 可以这么说，管程就是一把解决并发问题的万能钥匙。



## 什么是管程

- Java 在 1.5 之前仅仅提供了 synchronized 关键字及 wait()、notify()、notifyAll() 这三个看似从天而降的方法
- 管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。但是管程更容易使用，所以 Java 选择了管程。
- 管程，对应的英文是 `Monitor`，很多 Java 领域的同学都喜欢将其翻译成“监视器”，这是直译。操作系统领域一般都翻译成“管程”，这个是意译。
- 所谓管程
  - **指的是管理共享变量以及对共享变量的操作过程，让他们支持并发**。
  - 用Java语言描述，管理类的成员变量和成员方法，让这个类是线程安全的。





## MESA 模型

- 出现过3种管程模型：Hasen 模型、Hoare 模型和 `MESA` 模型。

- 2大核心问题（管程可以解决）

  - 互斥，即同一时刻只允许一个线程访问共享资源；
  - 同步，即线程之间如何通信、协作。

- 如何解决互斥问题
  - 将共享变量及其对共享变量的操作统一封装起来。

- 如何解决同步问题
  - 引入条件变量的概念，每个条件变量都对应有一个等待队列

- wait() 的正确姿势
  - 需要在一个 while 循环里面调用 wait()

  ```java
  while(条件不满足) {
    wait();
  }
  ```

- notify() 何时可以使用（要满足以下三个条件）

  - 所有等待线程拥有相同的等待条件；
  - 所有等待线程被唤醒后，执行相同的操作；
  - 只需要唤醒一个线程。

- 总结

  - 管程是一个解决并发问题的模型，可以参考医院就医的流程来加深理解。重点在于理解条件变量及其等待队列的工作原理。
  - MESA 模型中，条件变量可以有多个，Java 语言内置的管程里只有一个条件变量。
    - Java 内置的管程方案（synchronized）使用简单，synchronized 关键字修饰的代码块，在编译期会自动生成相关加锁和解锁的代码，但是仅支持一个条件变量
    - 而 Java SDK 并发包实现的管程支持多个条件变量，不过并发包里的锁，需要开发人员自己进行加锁和解锁操作。





# 9 线程的生命周期



![](./img/生命周期.png)



- 五态模型
  - 【初始状态】：指的是线程已经被创建（编程语言层面），但是还不允许分配 CPU 执行。
  - 【可运行状态】：线程可以分配 CPU 执行。
  - 当有空闲的 CPU 时，操作系统会将其分配给一个处于可运行状态的线程，被分配到 CPU 的线程的状态就转换成了【运行状态】。
  - 运行状态的线程如果调用一个阻塞的 API（例如以阻塞方式读文件）或者等待某个事件（例如条件变量），那么线程的状态就会转换到【休眠状态】，同时释放 CPU 使用权
  - 线程执行完或者出现异常就会进入【终止状态】，也就意味着线程的生命周期结束了。

- Java 中线程生命周期
  - NEW（初始化状态）
  - RUNNABLE（可运行 / 运行状态）
  - BLOCKED（阻塞状态）
  - WAITING（无时限等待）
  - TIMED_WAITING（有时限等待）
  - TERMINATED（终止状态）

- 在操作系统层面，Java 线程中的 `BLOCKED`、`WAITING`、`TIMED_WAITING` 是一种状态，即前面我们提到的休眠状态。
  - 也就是说只要 Java 线程处于这三种状态之一，那么这个线程就永远没有 CPU 的使用权。

- 五状态
  - 线程的生命周期分为新建（New）、就绪（Runnable）、运行（Running）、阻塞（Blocked） 和死亡（Dead）这 5种状态。
  - 在系统运行过程中不断有新的线程被创建，旧的线程在执行完毕后被清理，线程在排队获取共享资源或者锁时将被阻塞。
  - 因此运行中的线程会在就绪、阻塞、运行状态之间来回切换。线程的具体状态转化流程如图所示。



![](https://notes2021.oss-cn-beijing.aliyuncs.com/2021/image-20220601152944877.png)





## RUNNABLE 与 BLOCKED 的状态转换

- 只有一种场景会触发这种转换，就是线程等待 `synchronized` 的隐式锁。
  - 当等待的线程获得 synchronized 隐式锁时，就又会从 BLOCKED 转换到 RUNNABLE 状态。

- JVM 层面并不关心操作系统调度相关的状态
  - 在 JVM 看来，等待 CPU 使用权（操作系统层面此时处于可执行状态）与等待 I/O（操作系统层面此时处于休眠状态）没有区别，都是在等待某个资源，所以都归入了 `RUNNABLE` 状态。
  - 我们平时所谓的 Java 在调用阻塞式 API 时，线程会阻塞，指的是操作系统线程的状态，并不是 Java 线程的状态。

## RUNNABLE 与 WAITING 的状态转换

- 场景1，获得 `synchronized` 隐式锁的线程，调用无参数的 Object.wait() 方法。
- 场景2，调用无参数的` Thread.join()` 方法（线程同步方法）。
  - 例如有一个线程对象 thread A，当调用 A.join() 的时候，执行这条语句的线程会等待 thread A 执行完，而等待中的这个线程，其状态会从 RUNNABLE 转换到 WAITING。
  - 当线程 thread A 执行完，原来等待它的线程又会从 WAITING 状态转换到 RUNNABLE。
- 场景3，调用 `LockSupport.park()` 方法。
  - 其中的 `LockSupport` 对象，也许你有点陌生，其实 Java 并发包中的锁，都是基于它实现的。
  - 调用 `LockSupport.park()` 方法，当前线程会阻塞，线程的状态会从 RUNNABLE 转换到 WAITING。
  - 调用 `LockSupport.unpark(Thread thread)` 可唤醒目标线程，目标线程的状态又会从 WAITING 状态转换到 RUNNABLE。

## RUNNABLE 与 TIMED_WAITING 的状态转换

- 调用**带超时参数**的 `Thread.sleep(long millis)` 方法；
- 获得 synchronized 隐式锁的线程，调用**带超时参数**的`Object.wait(long timeout)` 方法；
- 调用**带超时参数**的 `Thread.join(long millis)` 方法；
- 调用带超时参数的 LockSupport.parkNanos(Object blocker, long deadline) 方法；
- 调用带超时参数的 LockSupport.parkUntil(long deadline) 方法。

你会发现 `TIMED_WAITING` 和 `WAITING` 状态的区别，仅仅是触发条件多了超时参数。



## 从 NEW 到 RUNNABLE 状态

- Java 刚创建出来的 Thread 对象就是 NEW 状态

  - NEW 状态的线程，不会被操作系统调度，因此不会执行。

  - Java 线程要执行，就必须转换到 RUNNABLE 状态。只要调用线程对象的` start() `方法就可以了。

    ```java
    MyThread myThread = new MyThread();
    // 从NEW状态转换到RUNNABLE状态
    myThread.start();
    ```

    

- 而创建 Thread 对象主要有两种方法。

  - 一种是继承 Thread 对象，重写 run() 方法。

  ```java
  // 自定义线程对象
  class MyThread extends Thread {
    public void run() {
      // 线程需要执行的代码
      ......
    }
  }
  // 创建线程对象
  MyThread myThread = new MyThread();
  ```

  - 另一种是实现 Runnable 接口，重写 run() 方法，并将该实现类作为创建 Thread 对象的参数。

  ```java
  // 实现Runnable接口
  class Runner implements Runnable {
    @Override
    public void run() {
      // 线程需要执行的代码
      ......
    }
  }
  // 创建线程对象
  Thread thread = new Thread(new Runner());
  ```

## 从 RUNNABLE 到 TERMINATED 状态

- 线程执行完 run() 方法后，会自动转换到 TERMINATED 状态。
- 当然如果执行 run() 方法的时候异常抛出，也会导致线程终止。
- 有时需要强制中断 run() 方法的执行，
  - 例如 run() 方法访问一个很慢的网络，我们等不下去了，想终止怎么办呢？
  - Java 的 Thread 类里面倒是有个 stop() 方法，不过已经标记为 @Deprecated，所以不建议使用了。
  - 正确的姿势其实是调用 `interrupt()` 方法。
- 那 `stop()` 和 `interrupt()` 方法的主要区别是什么呢？
  - stop() 方法会真的**杀死线程**，不给线程喘息的机会，
    - 如果线程持有 ReentrantLock 锁，被 stop() 的线程并不会自动调用 ReentrantLock 的 unlock() 去释放锁，那其他线程就再也没机会获得 ReentrantLock 锁，这实在是太危险了。
    - 所以该方法就不建议使用了，类似的方法还有 suspend() 和 resume() 方法，这两个方法同样也都不建议使用了。
  - 而 interrupt() 方法就温柔多了，interrupt() 方法**仅仅是通知线程，线程有机会执行一些后续操作**，同时也可以无视这个通知。被 interrupt 的线程，是怎么收到通知的呢？一种是异常，另一种是主动检测。





# 10  创建多少线程才是合适的？

工作中，经常有人问，“各种线程池的线程数量调整成多少是合适的？”或者“Tomcat 的线程数、Jdbc 连接池的连接数是多少？”等等。
那我们应该如何设置合适的线程数呢？分析一下：

- 为什么要使用多线程？
  - 主要是降低延迟（响应时间），提高吞吐量（单位时间内能处理请求的数量）。
    - 一个方向是优化算法，另一个方向是将硬件的性能发挥到极致。
    - 提升 I/O 和 CPU 的综合利用率。
  - 两个指标内部有一定的联系（同等条件下，延迟越短，吞吐量越大），但是由于它们隶属不同的维度（一个是时间维度，一个是空间维度），并不能互相转换。
- 多线程的应用场景有哪些？
  - 如果 CPU 和 I/O 设备的利用率都很低，那么可以尝试通过增加线程来提高吞吐量。
- 创建多少线程合适？
  - I/O 密集型程序和 CPU 密集型程序，计算最佳线程数的方法是不同的。
  - 对于 **CPU 密集型**的计算场景，理论上“线程的数量 =CPU 核数”就是最合适的。
    - 不过在工程上，线程的数量一般会设置为“**CPU 核数 +1**”
  - 对于 **I/O 密集型**的计算场景：最佳线程数 =**CPU 核数 * [ 1 +（I/O 耗时 / CPU 耗时）]**
    - I/O 耗时和 CPU 耗时的比值是一个关键参数。我们要估算这个参数，然后做各种不同场景下的压测来验证我们的估计。



# 11 为什么局部变量是线程安全的？

- 多个线程同时访问共享变量的时候，会导致并发问题。

- `fibonacci()` 方法

  - 会根据传入的参数 `n` ，返回 1 到 n 的斐波那契数列
  - 斐波那契数列类似这样： 1、1、2、3、5、8、13、21、34……第 1 项和第 2 项是 1，从第 3 项开始，每一项都等于前两项之和。
  - 在这个方法里面，有个局部变量：数组 `r` 用来保存数列的结果，每次计算完一项，都会更新数组 r 对应位置中的值。
  - 当多个线程调用 fibonacci() 这个方法的时候，数组 r 是否存在数据竞争（Data Race）呢？

  ```java
  // 返回斐波那契数列
  int[] fibonacci(int n) {
    // 创建结果数组
    int[] r = new int[n];
    // 初始化第一、第二个数
    r[0] = r[1] = 1;  // ①
    // 计算2..n
    for(int i = 2; i < n; i++) {
        r[i] = r[i-2] + r[i-1];
    }
    return r;
  }
  ```

  - 局部变量不存在数据竞争，为什么？
    - CPU 层面，是没有方法概念的，CPU 的眼里，只有一条条的指令。（编译原理）
    - 可以站在编译器实现者的角度来思考“怎么完成方法到指令的转换”。

## 方法是如何被执行的

- CPU 通过 CPU 的堆栈寄存器 找到调用方法的参数和返回地址。

- 调用栈
  - 每个方法在调用栈里都有自己的独立空间，称为**栈帧**，每个栈帧里都有**对应方法需要的参数和返回地址**。
  - 当调用方法时，会创建新的栈帧，并压入调用栈；当方法返回时，对应的栈帧就会被自动弹出。
  - 也就是说，栈帧和方法是同生共死的。

## 局部变量存哪里？

- 局部变量的作用域是方法内部，也就是说当方法执行完，局部变量就没用了，局部变量应该和方法同生共死。
- **局部变量就是放到了调用栈里。**

## 调用栈与线程的关系

- 每个线程都有自己独立的调用栈。
- 篇首的问题：Java 方法里面的局部变量是否存在并发问题？
  - 一点问题都没有。
  - 因为每个线程都有自己的调用栈，局部变量保存在线程各自的调用栈里面，不会共享，所以自然也就没有并发问题。
  - 再次重申一遍：没有共享，就没有伤害。



## 线程封闭

- 线程封闭：方法里的局部变量，因为不会和其他线程共享，所以没有并发问题。
- 采用线程封闭技术的案例非常多。
  - 例如从数据库连接池里获取的连接 Connection。
  - JDBC 规范里并没有要求这个 Connection 必须是线程安全的。
  - 数据库连接池通过线程封闭技术，保证一个 Connection 一旦被一个线程获取之后，在这个线程关闭 Connection 之前的这段时间里，不会再分配给其他线程，从而保证了 Connection 不会有并发问题。

## 总结

- 建议你也多研究原理性的东西、通用的东西，有这些东西之后再学具体的技术就快多了。



# 12 如何用面向对象思想写好并发程序？

## 封装共享变量
- 将共享变量作为对象属性封装在内部，对所有公共方法制定并发访问策略。 
- 对于不会发生变化的共享变量，建议用 final 关键字来修饰。

## 识别共享变量间的约束条
- 反映在代码里，基本上都会有 if 语句，一定要特别注意竞态条件。

## 制定并发访问策略
- 避免共享：避免共享的技术主要是利于线程本地存储以及为每个任务分配独立的线程。 
- 不变模式：Java 领域应用的很少
- 管程及其他同步工具
  - Java 领域万能的解决方案是管程。
  - 但是对于很多特定场景，使用 Java 并发包提供的读写锁、并发容器等同步工具会更好。
- 后面的第二模块会仔细讲解 Java 并发工具类以及他们的应用场景。第三模块还会讲解并发编程的设计模式。
- 一些宏观原则，有助于你写出“健壮”的并发程序。
  - 优先使用成熟的工具类：`Java SDK` 并发包里提供了丰富的工具类，基本上能满足你日常的需要。
    - 建议你熟悉它们，用好它们，而不是自己再“发明轮子”
  - 迫不得已时才使用低级的同步原语：低级的同步原语主要指的是 `synchronized`、`Lock`、`Semaphore `等
    - 这些虽然感觉简单，但实际上并没那么简单，一定要小心使用。
  - 避免过早优化：安全第一，并发程序首先要保证安全，出现性能瓶颈后再优化。

# 13 理论基础模块热点问题总结

## 串行的故事

![img](https://static001.geekbang.org/resource/image/7f/8e/7fed6a485a694c794ee205c346b5338e.png?wh=2820*1178)



## 用锁的最佳实践

- 一个基本的原则：锁，应是私有的、不可变的、不可重用的。

```java
// 普通对象锁
private final Object lock = new Object();
// 静态对象锁
private static final Object lock = new Object(); 
```





## 竞态条件需要格外关注



## 方法调用是先计算参数



## InterruptedException 异常处理需小心

- 在触发 `InterruptedException` 异常的同时，JVM 会同时把线程的中断标志位清除



## 理论值 or 经验值

- 实际工作中，不同的` I/O` 模型对最佳线程数的影响非常大
  - 例如大名鼎鼎的 `Nginx` 用的是非阻塞 I/O，采用的是多进程单线程结构
  - Nginx 本来是一个`I/O` 密集型系统，但是最佳进程数设置的却是 `CPU` 的核数，完全参考的是 `CPU` 密集型的算法



## 总结

- 推荐认真阅读《Java 安全编码标准》这本书





以下是并发工具类（14讲）部分。





# 14 Lock和Condition（上）：隐藏在并发包中的管程

Java SDK 并发包通过 Lock 和 Condition 两个接口来实现管程，其中 `Lock` 用于解决互斥问题，`Condition` 用于解决同步问题。

思考一下：Java 语言本身提供的 synchronized 也是管程的一种实现，既然 Java 从语言层面已经实现了管程了，那为什么还要在 SDK 里提供另外一种实现呢？

## 再造管程的理由

对于死锁问题，提出了一个破坏不可抢占条件方案，但是这个方案 `synchronized` 没有办法解决。原因是 synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。

但是我们希望的是，对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。如何重新设计一把互斥锁去解决这个问题？

- **能够响应中断**。synchronized 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程。但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有机会释放曾经持有的锁 A。这样就破坏了不可抢占条件了。
- **支持超时**。如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。
- **非阻塞地获取锁**。如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。



这三种方案可以全面弥补 synchronized 的问题。体现在 API 上，就是 Lock 接口的三个方法。

```java
// 支持中断的API
void lockInterruptibly() throws InterruptedException;
// 支持超时的API
boolean tryLock(long time, TimeUnit unit) throws InterruptedException;
// 支持非阻塞获取锁的API
boolean tryLock();
```



## 如何保证可见性

Java SDK 里面 Lock 的使用，有一个经典的范例，就是 `try{}finally{}`，需要重点关注的是在 finally 里面释放锁。

已经知道 Java 里多线程的可见性是通过 `Happens-Before` 规则保证的，而 `synchronized` 之所以能够保证可见性，也是因为有一条 synchronized 相关的规则：synchronized 的解锁 Happens-Before 于后续对这个锁的加锁。

如下代码，线程 T1 对 value 进行了 +=1 操作，那后续的线程 T2 能够看到 value 的正确结果吗？

```java

class X {
  private final Lock rtl = new ReentrantLock();
  int value;
  
  public void addOne() {
    // 获取锁
    rtl.lock();  
    try {
      value+=1;
    } finally {
      // 保证锁能释放
      rtl.unlock();
    }
  }
}
```

答案必须是肯定的。

Java SDK 里面锁的实现非常复杂，原理简单介绍就是：利用了 `volatile` 相关的 Happens-Before 规则。Java SDK 里面的 ReentrantLock，内部持有一个 volatile 的成员变量 `state`，获取锁的时候，会读写 state 的值；解锁的时候，也会读写 state 的值（简化后的代码如下面所示）。也就是说，在执行 value+=1 之前，程序先读写了一次 volatile 变量 state，在执行 value+=1 之后，又读写了一次 volatile 变量 state。根据相关的 Happens-Before 规则：

1. 顺序性规则：对于线程 T1，value+=1 Happens-Before 释放锁的操作 unlock()；
2. volatile 变量规则：由于 state = 1 会先读取 state，所以线程 T1 的 unlock() 操作 Happens-Before 线程 T2 的 lock() 操作；
3. 传递性规则：线程 T1 的 value+=1 Happens-Before 线程 T2 的 lock() 操作。

```java

class SampleLock {
  volatile int state;
  // 加锁
  lock() {
    // 省略代码无数
    state = 1;
  }
  // 解锁
  unlock() {
    // 省略代码无数
    state = 0;
  }
}
```



所以说，后续线程 T2 能够看到 value 的正确结果。



## 可重入锁

ReentrantLock，翻译过来叫可重入锁。所谓可重入锁，顾名思义，指的是线程可以重复获取同一把锁。

如下代码，当线程 T1 执行到 ① 处时，已经获取到了锁 rtl ，**当在 ① 处调用 get() 方法时，会在 ② 再次对锁 rtl 执行加锁操作**。此时，如果锁 rtl 是可重入的，那么线程 T1 可以再次加锁成功；如果锁 rtl 是不可重入的，那么线程 T1 此时会被阻塞。

```java
class X {
  private final Lock rtl = new ReentrantLock();
  int value;
  
  public int get() {
    // 获取锁
    rtl.lock();         ②
    try {
      return value;
    } finally {
      // 保证锁能释放
      rtl.unlock();
    }
  }
  public void addOne() {
    // 获取锁
    rtl.lock();  
    try {
      value = 1 + get(); ①
    } finally {
      // 保证锁能释放
      rtl.unlock();
    }
  }
}
```

所谓**可重入函数，指的是多个线程可以同时调用该函数**，每个线程都能得到正确结果；同时在一个线程内支持线程切换，无论被切换多少次，结果都是正确的。多线程可以同时执行，还支持线程切换，这意味着什么呢？线程安全啊。所以，**可重入函数是线程安全的**。



## 公平锁与非公平锁

ReentrantLock 这个类有两个构造函数，一个是无参构造函数，一个是传入 `fair` 参数的构造函数。fair 参数代表的是锁的公平策略，如果传入 true 就表示需要构造一个公平锁，反之则表示要构造一个非公平锁。



```java
//无参构造函数：默认非公平锁
public ReentrantLock() {
    sync = new NonfairSync();
}
//根据公平策略参数创建锁
public ReentrantLock(boolean fair){
    sync = fair ? new FairSync() : new NonfairSync();
}
```

锁都对应着一个等待队列，如果一个线程没有获得锁，就会进入等待队列，当有线程释放锁的时候，就需要从等待队列中唤醒一个等待的线程。如果是公平锁，唤醒的策略就是谁等待的时间长，就唤醒谁，很公平；如果是非公平锁，则不提供这个公平保证，有可能等待时间短的线程反而先被唤醒。



## 用锁的最佳实践

- 永远只在更新对象的成员变量时加锁
- 永远只在访问可变的成员变量时加锁
- 永远不在调用其他对象的方法时加锁



## 总结

Java SDK 并发包里的 Lock 接口里面的每个方法，你可以感受到，都是经过深思熟虑的。

除了支持类似 synchronized 隐式加锁的 lock() 方法外，还支持超时、非阻塞、可中断的方式获取锁，这三种方式为我们编写更加安全、健壮的并发程序提供了很大的便利。





# 15 Lock和Condition（下）：Dubbo如何用管程实现异步转同步？

## 同步与异步

通俗点来讲就是调用方是否需要等待结果，如果需要等待结果，就是同步；如果不需要等待结果，就是异步。

同步，是 Java 代码默认的处理方式。如果你想让你的程序支持异步，可以通过下面两种方式来实现：

1. 调用方创建一个子线程，在子线程中执行方法调用，这种调用我们称为异步调用；
2. 方法实现的时候，创建一个新的线程执行主要逻辑，主线程直接 return，这种方法我们一般称为异步方法。





## Dubbo 源码分析

在 TCP 协议层面，发送完 RPC 请求后，线程是不会等待 RPC 的响应结果的。平时工作中的 RPC 调用大多数都是同步的啊？

有人帮你做了异步转同步的事情。例如目前知名的 RPC 框架 Dubbo 就给我们做了异步转同步的事情。

对于下面一个简单的 RPC 调用，默认情况下 sayHello() 方法，是个同步方法，也就是说，执行 service.sayHello(“dubbo”) 的时候，线程会停下来等结果。

```java
DemoService service = 初始化部分省略
String message = service.sayHello("dubbo");
System.out.println(message);
```

如果此时你将调用线程 dump 出来的话，会是下图这个样子，你会发现调用线程阻塞了，线程状态是 TIMED_WAITING。本来发送请求是异步的，但是调用线程却阻塞了，说明 Dubbo 帮我们做了异步转同步的事情。

通过调用栈，你能看到线程是阻塞在 `DefaultFuture.get()` 方法上，所以可以推断：Dubbo 异步转同步的功能应该是通过 `DefaultFuture` 这个类实现的。

DubboInvoker 的 108 行调用了 DefaultFuture.get()，这一行很关键。

经典的等待 - 通知机制

```java
// 创建锁与条件变量
private final Lock lock = new ReentrantLock();
private final Condition done = lock.newCondition();

// 调用方通过该方法等待结果
Object get(int timeout){
  long start = System.nanoTime();
  lock.lock();
  try {
  while (!isDone()) {
    done.await(timeout);
      long cur=System.nanoTime();
    if (isDone() || 
          cur-start > timeout){
      break;
    }
  }
  } finally {
  lock.unlock();
  }
  if (!isDone()) {
  throw new TimeoutException();
  }
  return returnFromResponse();
}
// RPC结果是否已经返回
boolean isDone() {
  return response != null;
}
// RPC结果返回时调用该方法   
private void doReceived(Response res) {
  lock.lock();
  try {
    response = res;
    if (done != null) {
      done.signal();
    }
  } finally {
    lock.unlock();
  }
}
```



调用线程通过调用 get() 方法等待 RPC 返回结果，这个方法里面，调用 `lock()` 获取锁，在 finally 里面调用 `unlock()` 释放锁；获取锁后，通过经典的在循环中调用 `await()` 方法来实现等待。



当 RPC 结果返回时，会调用 `doReceived()` 方法，这个方法里面，调用 `lock()` 获取锁，在 finally 里面调用 `unlock()` 释放锁，获取锁后通过调用 `signal()` 来通知调用线程，结果已经返回，不用继续等待了。

至此，Dubbo 里面的异步转同步的源码就分析完了。



## 总结

Lock&Condition 实现的管程相对于 synchronized 实现的管程来说更加灵活、功能也更丰富。



# 16 Semaphore：如何快速实现一个限流器？

## 信号量模型

可以概括为：**一个计数器，一个等待队列，三个方法**。在信号量模型里，计数器和等待队列对外是透明的，所以只能通过信号量模型提供的三个方法来访问它们，这三个方法分别是：init()、down() 和 up()。

![image-20230217215914709](https://notes2021.oss-cn-beijing.aliyuncs.com/2021/image-20230217215914709.png)

- init()：设置计数器的初始值。
- down()：计数器的值减 1；如果此时计数器的值小于 0，则当前线程将被阻塞，否则当前线程可以继续执行。
- up()：计数器的值加 1；如果此时计数器的值小于或者等于 0，则唤醒等待队列中的一个线程，并将其从等待队列中移除。

三个方法都是原子性的，并且这个原子性是由信号量模型的实现方保证的。在 Java SDK 里面，信号量模型是由 `java.util.concurrent.Semaphore` 实现的，Semaphore 这个类能够保证这三个方法都是原子操作。



## 如何使用信号量



```java
static int count;
//初始化信号量
static final Semaphore s = new Semaphore(1);
//用信号量保证互斥    
static void addOne() {
  s.acquire();
  try {
    count+=1;
  } finally {
    s.release();
  }
}
```







## 快速实现一个限流器



```java

class ObjPool<T, R> {
  final List<T> pool;
  // 用信号量实现限流器
  final Semaphore sem;
  // 构造函数
  ObjPool(int size, T t){
    pool = new Vector<T>(){};
    for(int i=0; i<size; i++){
      pool.add(t);
    }
    sem = new Semaphore(size);
  }
  // 利用对象池的对象，调用func
  R exec(Function<T,R> func) {
    T t = null;
    sem.acquire();
    try {
      t = pool.remove(0);
      return func.apply(t);
    } finally {
      pool.add(t);
      sem.release();
    }
  }
}
// 创建对象池
ObjPool<Long, String> pool = 
  new ObjPool<Long, String>(10, 2);
// 通过对象池获取t，之后执行  
pool.exec(t -> {
    System.out.println(t);
    return t.toString();
});
```



## 总结

信号量在 Java 语言里面名气并不算大，但是在其他语言里却是很有知名度的。Java 在并发编程领域走的很快，重点支持的还是管程模型。



# 17 ReadWriteLock：如何快速实现一个完备的缓存？

## 快速实现一个缓存



```java

class Cache<K,V> {
  final Map<K, V> m = new HashMap<>();
  final ReadWriteLock rwl = new ReentrantReadWriteLock();
  // 读锁
  final Lock r = rwl.readLock();
  // 写锁
  final Lock w = rwl.writeLock();
  // 读缓存
  V get(K key) {
    r.lock();
    try { return m.get(key); }
    finally { r.unlock(); }
  }
  // 写缓存
  V put(K key, V value) {
    w.lock();
    try { return m.put(key, v); }
    finally { w.unlock(); }
  }
}
```





## 实现缓存的按需加载



```java

class Cache<K,V> {
  final Map<K, V> m = new HashMap<>();
  final ReadWriteLock rwl = new ReentrantReadWriteLock();
  final Lock r = rwl.readLock();
  final Lock w = rwl.writeLock();
 
  V get(K key) {
    V v = null;
    //读缓存
    r.lock();         ①
    try {
      v = m.get(key); ②
    } finally{
      r.unlock();     ③
    }
    //缓存中存在，返回
    if(v != null) {   ④
      return v;
    }  
    //缓存中不存在，查询数据库
    w.lock();         ⑤
    try {
      //再次验证
      //其他线程可能已经查询过数据库
      v = m.get(key); ⑥
      if(v == null){  ⑦
        //查询数据库
        v=省略代码无数
        m.put(key, v);
      }
    } finally{
      w.unlock();
    }
    return v; 
  }
}
```



## 读写锁的升级与降级



```java
//读缓存
r.lock();         ①
try {
  v = m.get(key); ②
  if (v == null) {
    w.lock();
    try {
      //再次验证并更新缓存
      //省略详细代码
    } finally{
      w.unlock();
    }
  }
} finally{
  r.unlock();     ③
}
```



## 总结







# 18 StampedLock：有没有比读写锁更快的锁？

# 19 CountDownLatch和CyclicBarrier：如何让多线程步调一致？

# 20 并发容器：都有哪些“坑”需要我们填？

# 21 原子类：无锁工具类的典范

# 22 Executor与线程池：如何创建正确的线程池？

# 23 Future：如何用多线程实现最优的“烧水泡茶”程序？

# 24 CompletableFuture：异步编程没那么难

# 25 CompletionService：如何批量执行异步任务？

# 26 Fork/Join：单机版的MapReduce









